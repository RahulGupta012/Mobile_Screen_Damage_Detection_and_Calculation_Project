# -*- coding: utf-8 -*-
"""mobile_detection_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A5WfSlUcT7zLnuiZjleK23nY3tEU3gvh
"""

import zipfile
import os
!apt-get install unrar
!pip install rarfile
import rarfile

import random
import shutil
import xml.etree.ElementTree as ET
from PIL import Image
import re
import os

!pip install ultralytics
import ultralytics
from ultralytics import YOLO


zipfile.ZipFile('/content/annotations.zip' , 'r').extractall('/content/ann_dir')
rarfile.RarFile('/content/selected_zip.rar').extractall('/content/img_dir')

img_dir = '/content/img_dir'
ann_dir = '/content/ann_dir'

# Define paths for the YOLOv8 dataset structure
yolo_dataset_root = '/content/yolo_dataset'
yolo_images_train = os.path.join(yolo_dataset_root, 'train', 'images')
yolo_labels_train = os.path.join(yolo_dataset_root, 'train', 'labels')
yolo_images_val = os.path.join(yolo_dataset_root, 'val', 'images')
yolo_labels_val = os.path.join(yolo_dataset_root, 'val', 'labels')

# Create directories
os.makedirs(yolo_images_train, exist_ok=True)
os.makedirs(yolo_labels_train, exist_ok=True)
os.makedirs(yolo_images_val, exist_ok=True)
os.makedirs(yolo_labels_val, exist_ok=True)

# Function to convert XML to YOLO format
def convert_xml_to_yolo(xml_filepath, img_filepath, output_label_dir, class_name_to_id={'cracked_screen': 0}):
    tree = ET.parse(xml_filepath)
    root = tree.getroot()

    img = Image.open(img_filepath)
    img_width, img_height = img.size

    yolo_lines = []
    for obj in root.findall('object'):
        class_name = obj.find('name').text
        if class_name in class_name_to_id:
            class_id = class_name_to_id[class_name]
            bndbox = obj.find('bndbox')
            xmin = int(float(bndbox.find('xmin').text))
            ymin = int(float(bndbox.find('ymin').text))
            xmax = int(float(bndbox.find('xmax').text))
            ymax = int(float(bndbox.find('ymax').text))

            # Normalize coordinates and convert to YOLO format
            x_center = (xmin + xmax) / (2 * img_width)
            y_center = (ymin + ymax) / (2 * img_height)
            width = (xmax - xmin) / img_width
            height = (ymax - ymin) / img_height

            yolo_lines.append(f"{class_id} {x_center} {y_center} {width} {height}")

    if yolo_lines:
        label_filename = os.path.basename(xml_filepath).replace('.xml', '.txt')
        with open(os.path.join(output_label_dir, label_filename), 'w') as f:
            f.write("\n".join(yolo_lines))

def get_base_name(filepath):
    return os.path.splitext(os.path.basename(filepath))[0]

# Get all image files from the original directory
all_img_files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

all_xml_files = []
for root, _, files in os.walk(ann_dir):
    for file in files:
        if file.lower().endswith('.xml') and not file.startswith('._'):
            all_xml_files.append(os.path.join(root, file))

# Create a dictionary for quick lookup of XMLs by their base name
xml_basenames = {get_base_name(xml_file): xml_file for xml_file in all_xml_files}

# Filter XML annotation
annotated_img_files = []
for img_filename in all_img_files:
    img_basename = get_base_name(img_filename) # Correctly get basename without path or extension
    found_xml_path = None

    # Exact basename match
    if img_basename in xml_basenames:
        found_xml_path = xml_basenames[img_basename]
    else:
        # Numeric match for patterns
        match = re.search(r'\((\d+)\)', img_basename)
        if match:
            numeric_basename = match.group(1)
            if numeric_basename in xml_basenames:
                found_xml_path = xml_basenames[numeric_basename]

    if found_xml_path:
        annotated_img_files.append((img_filename, found_xml_path))
    else:
        print(f"Warning: No XML annotation found for image {img_filename} (tried exact match and numeric match)")

random.shuffle(annotated_img_files)

# Split annotated  into training and validation sets
train_pairs = annotated_img_files[:int(len(annotated_img_files) * 0.8)]
val_pairs = annotated_img_files[int(len(annotated_img_files) * 0.8):]

print(f"Number of training images for YOLOv8: {len(train_pairs)}")
print(f"Number of validation images for YOLOv8: {len(val_pairs)}")

# copy images and convert annotations for training
for img_filename, xml_filepath in train_pairs:
    img_src_path = os.path.join(img_dir, img_filename)
    shutil.copy(img_src_path, yolo_images_train)
    convert_xml_to_yolo(xml_filepath, img_src_path, yolo_labels_train)

# copy images and convert annotations for validation
for img_filename, xml_filepath in val_pairs:
    img_src_path = os.path.join(img_dir, img_filename)
    shutil.copy(img_src_path, yolo_images_val)
    convert_xml_to_yolo(xml_filepath, img_src_path, yolo_labels_val)

# Create dataset
data_yaml_path = os.path.join(yolo_dataset_root, 'data.yaml')
with open(data_yaml_path, 'w') as f:
    f.write(f"path: {yolo_dataset_root}\n")
    f.write("train: train/images\n")
    f.write("val: val/images\n")
    f.write("\n")
    f.write("nc: 1  # number of classes\n")
    f.write("names: ['cracked_screen']  # class names\n")

print(f"YOLOv8 data.yaml created at: {data_yaml_path}")


# Training the model

model = ultralytics.YOLO('yolov8n.pt')

model.train(data= data_yaml_path, epochs=15)

model.save('mobile_detector.pt')

print(model.eval())